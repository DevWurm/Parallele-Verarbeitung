\chapter{Umsetzung von Parallelität auf Hardwareebene}
Um parallelisierte Anwendungen parallel auszuführen, benötigt es Hardwarekomponenten, die eine solche Verarbeitung erlauben. Das dafür verantwortliche Element ist hauptsächlich der Prozessor. Auch andere Komponenten, wie der etwa \ac{RAM} Spielen dabei eine gewisse Rolle, doch darauf soll hier nicht weiter eingegangen werden.\\
Im folgenden Kapitel umfasst der Begriff Thread (wenn nicht explizit ausgeschlossen) immer auch die Möglichkeit des Prozesses, da jeder Prozess aus mindestens einem Thread besteht und die Behandlung von Threads und Prozessen auf Hardwareebene somit größtenteils kongruent ist.\\
Eine parallele Verarbeitung findet nur statt, wenn die verschiedenen Subroutinen eines Programms auch tatsächlich gleichzeitig ausgeführt werden. Dies ist bei Recheneinheiten mit mehreren Rechenkernen (Multicoreprozessoren) problemlos möglich und vorgesehen. Allerdings werden auch Möglichkeiten geschaffen, eine scheinbare oder sogar tatsächliche parallele Verarbeitung auf Einkernprozessoren zu realisieren.

\section{Einkernprozessoren}
Da Einzelkernprozessoren nur eine Recheneinheit besitzen, werden software- und hardwareseitige Lösungen geschaffen, um einige Vorteile der parallelen Verarbeitung dennoch zu nutzen. Darunter fällt weniger die Leistungssteigerung des ausgeführten Programms, da die Leistungsfähigkeit der benutzten Recheneinheit nicht verändert wird, wohl aber Vorteile, wie die zeitnahe Aktualisierung grafischer Oberflächen oder Abfrage von Sensoren und die Durchführung von Vergleichsprozessen.

\subsection{Multiplexverfahren} \label{multiplexing}
Multiplexverfahren (auch Scheduling) sind Methoden, bei denen ein beschränktes Medium (in diesem Falle der Prozessor mit seiner Beschränkung auf die sequentielle Verarbeitung) nach bestimmten Mustern aufgeteilt wird um mehreren Inanspruchnehmern (in diesem Falle mehrere Threads, welche Rechenzeit anfordern) der Ressource gleichmäßigen oder der Priorität entsprechenden Zugang zu dieser zu gewähren. \cite{ITWissen_Multiplexverfahren} Sie sind somit ein Teil des Ressource-Sharing-Prozesses.\\
Das Multiplexing für Prozessoren wird auf der Softwareebene des Betriebssystems durchgeführt. \cite{Assmus_Softwarestrukturen}[S.2] Dabei handelt es sich nicht um eine parallele Ausführung, da die verschiedenen Routinen immer nacheinander bzw. zeitlich durchmischt ausgeführt werden. Für das Multiplexing von, für die Parallelisierung ausgelegter Software, wird ausgenutzt, dass jeder parallele Algorithmus auch nebenläufig ist und seine Subroutinen so unabhängig voneinander, auch zeitlich versetzt ausgeführt werden können.

\subsubsection{Zeitmultiplexverfahren}
Beim Zeitmultiplexverfahren wird die verfügbare Rechenzeit des Prozessors gleichmäßig oder der Priorität entsprechend auf die verschiedenen wartenden Threads verteilt. Haben alle Inanspruchnehmer die gleiche Priorität, dann werden die Intervalle möglichst gleichmäßig verteilt.\cite{Gumm_Einfurung}[S.550]\\
Die Zeitintervalle, die den Threads zugeteilt werden, sind in der Regel sehr kurz, was den Anschein eines parallelen Betriebs erzeugt und ausreicht, um einige Ansprüche an die parallele Verarbeitung näherungsweise zu erfüllen.\\
Ein Beispiel dafür wäre die Aktualisierung einer grafischen Oberfläche mit Daten aus einem zugehörigen parallel/nebenläufig ablaufenden Thread. Im Normalfall würden beide Routinen (Datenerzeugung und Aktualisierung der Oberfläche) gleichzeitig ablaufen. Werden sie, wie beim Zeitmultiplexverfahren, im kurzen Wechsel ausgeführt, ist das Ergebnis aus Sicht des Nutzers identisch. (Wenn Daten im Zeitabschnitt der Datenerzeugung erzeugt werden, werden sie im nächsten Zeitabschnitt der Aktualisierung in der Oberfläche umgesetzt.)\\
Da das Zeitmultiplexverfahren allgemein anwendbar ist, ist es bei der Ressourcenverwaltung weit verbreitet. In bestimmten Anwendungsfällen ist es allerdings günstiger, einem Thread nur dann Rechenzeit zuzusprechen, wenn er auch tatsächlich benötigt wird. Zu diesem Zweck existiert auch das Eventmultiplexverfahren.

\subsubsection{Eventmultiplexverfahren}
Beim Eventmultiplexing wird bestimmten Threads erst dann Rechenzeit zugeteilt, wenn eine bestimmte Situation eintritt (Event). Dies wird häufig bei \ac{I/O} Zugriffen, insbesondere bei der Netzwerkkommunikation angewendet. Mithilfe des Eventmultiplexings müssen dabei nicht mehrere Threads, die auf ihr Event warten, nebenläufig ausgeführt werden (was besonders bei Einkernprozessoren zu Problemen führen kann und die Leistung des Systems beeinträchtigt), sondern das Betriebssystem übernimmt diese Aufgabe und startet die in Ruhe versetzten Threads erst beim Auftreten des erwarteten Events. \cite{Han_Event_Multiplexing}\\
Ein Beispiel dazu ist eine Software, die zwei Sensoren auswertet. Die Bearbeitung der Daten wird mit einem Thread je Sensor ausgeführt. Auf einem Einkernprozessor würden die beiden Threads den Sensor regelmäßig abfragen und per Zeitmultiplexing abgewechselt werden. Nun ist es möglich, dass ein Sensor sein Event abgibt, wenn gerade der falsche Thread ausgeführt wird, was zu einem Fehler durch die ignorierte Meldung führen kann. Außerdem ist der Prozessor so mit zwei Threads, welche im Grunde keine Arbeit verrichten, stark ausgelastet. Eine Alternative (welche allerdings vom Betriebssystem bereitgestellt werden muss, wie es bei Linux \cite{Linux_Manual_Epoll} oder BSD \cite{BSD_Manual_Kqueue} der Fall ist) ist die Nutzung einer Betriebssystemschnittstelle, welche auf gesuchte Events wartet und beim Auftreten eines solchen dem zugehörigen Thread Rechenzeit startet. Auf die Events von mehreren Threads wird somit von einer Instanz auf Betriebssystemebene aus gewartet, was die Effizienz erhöht und die Fehleranfälligkeit vermindert.\\[0.5cm]
Multiplexverfahren können das Fehlen von Parallelität durch die Nutzung von einfacher Nebenläufigkeit in einigen Fällen recht gut kompensieren, doch für einige Anwendungen ist eine echte Parallelität notwendig. Auch diese ist unter gewissen Voraussetzungen auf Einkernprozessoren möglich.

\subsection{Simultaneous Multithreading}
Mithilfe des \ac{SMT} ist es möglich, eine tatsächliche Parallelität auf nur einem Rechenkern zu schaffen. Dazu wird die superskalare Architektur aktueller Prozessoren ausgenutzt. Diese ermöglicht es, die Berechnungen auf den einzelnen Rechenschaltkreisen im Rechenkern während eines Rechenzyklus parallel durchzuführen. Damit wird bereits prinzipiell eine Parallelisierung jedes bearbeiteten Threads auf tiefster Ebene durchgeführt, da Rechenanweisungen, zwischen denen offensichtlich keine Abhängigkeit besteht, in einem Zyklus gleichzeitig auf den verschiedenen Rechenschaltungen verarbeitet werden. (\textit{\glqq Modern superscalar processors can detect and exploit high levels of parallelism in the
instruction stream,  being able to begin execution of 3 to 5 instructions every cycle\grqq} \cite{Tullsen_Simultaneous_Multithreading}[S.1]) Um das zu erreichen, wird der Anweisungsstrom zum Prozessor durch eine sogenannte Pipeline-Schaltung geleitet, die ihn in die Teilschritte zerlegt, welche danach unabhängig durchgeführt werden können.\cite{Tullsen_Simultaneous_Multithreading}[S.1]\\
Diese Architektur wird bei der Konstruktion des \ac{SMT} ausgenutzt. Da die Recheneinheiten des Kerns unabhängig und parallel benutzt werden können, ist es möglich den Befehlsstrom mehrerer Threads (in der Regel zwei) in den Prozessorkern zu leiten, wodurch in einem Zyklus die Teilanweisungen von zwei Threads und damit die Threads selbst parallel auf nur einem Kern ausgeführt werden. Dazu wird dem Rechenkern eine zweite Pipeline-Schaltung vorgeschaltet, durch die der Anweisungsstrom des zweiten Threads in den Kern geleitet wird und ein zweiter Registersatz wird zur Verfügung gestellt, in dem die Rechendaten des zweiten Threads gespeichert werden.\cite{Tullsen_Simultaneous_Multithreading}[S.1]\\
Diese Praxis kann die Vorteile der Parallelität auch auf Einkernprozessoren nutzbar machen. Durch die bessere Ausnutzung der Prozessorschaltungen (Recheneinheiten, die ein Thread nicht benutzt, könnten u.U. durch den zweiten Thread benutzt werden) ist u.U. eine gewisse Leistungssteigerung möglich. Besonders bedeutsam ist allerdings die Parallelität auf Einkernprozessoren (z.B. bei Mikroprozessorsystemen) für die bereits genannten Anwendungen: \ac{I/O} Zugriffe mit mehreren Quellen (Netzwerke, Sensoren), \ac{GUI} Aktualisierungen oder Vergleichsprozesse.\\
Die \ac{SMT} Technik ist allgemein unter dem Markennamen \textit{Hyper-Threading} der Firma \textit{Intel} bekannt.\\[0.5 cm]
Das Multiprocessing auf einem Kern ist, sowohl für Mikroprozessoren als auch für Mehr-Kern-Systeme, sehr bedeutsam. Doch für Anwendungen, die mithilfe der Parallelisierung eine Signifikante Leistungssteigerung erreichen wollen oder eine hohe Anzahl an Threads benötigen, ist die Nutzung von Multicoreprozessoren dennoch unumgänglich.


\section{Mehrkernprozessoren}
Mehrkernprozessoren (auch Multicoreprozessoren) sind Prozessoren mit mehr als einem Rechenkern auf einem Chip. Alle Rechenkerne sind voneinander unabhängig, sie besitzen ihre eigenen Register, Pipelines, Datenleitungen und Schaltungen. \cite{Roloff_Multicore_Architekturen}[S.5, S.6] Mit entsprechenden Schnittstellen ist ein Mehrkernprozessor also multiprocessingfähig, da auf jedem Kern mindestens ein Prozess bzw. Thread ausgeführt werden kann. Ein Mehrkernprozessor kann also als ein Verbund aus Einkernprozessoren (allerdings mit sehr effizienten Ressourcenanbindungen (Speicher, etc.), da sich alle Recheneinheiten auf dem gleichen Chip befinden) betrachtet werden.\\
Die Vorteile von Multicoresystemen liegen zum einen im Bereich der Leistung, da bei voller Auslastung jeder Kern die Rechenleistung eines Einkernprozessors zur Gesamtleistung beisteuert, zum anderem im deutlich höheren Grad der Parallelisierung, da die übliche Anzahl an Kernen die maximal möglichen zwei Threads in einem Einkernprozessor bereits deutlich übersteigt. Im Privatmarkt sind zwei bis acht Kerne in einem Prozessor üblich, bei Serverprozessoren sind allerdings auch zehn bis 18 Kerne weit verbreitet. \cite{Stiller_Intels_Xeon} \\
Neben der reinen Erhöhung der Anzahl an Rechenkernen, kann die Leistungsfähigkeit von Mehrkernprozessoren auch durch die bereits genannten Methoden optimiert werden.

\subsection{Kombination von Parallelisierungsmethoden}
Um die Leistung von Mehrkernsystemen noch zu steigern, ist es möglich und üblich, die Optimierungs- und Leistungssteigerungsverfahren von Einkernprozessoren auf jeden Kern eines Mehrkernprozessors anzuwenden. Konventionelle Multicoreprozessoren unterstützen daher \ac{SMT} auf jedem Kern, wodurch ihre Leistungsfähigkeit stärker ausgenutzt wird und der Parallelisierungsgrad in der Regel verdoppelt wird.\\
Da bei regulären Systemen die Anzahl der laufenden Threads deutlich größer ist, als die vom Prozessor gleichzeitig abgearbeiteten Threads, muss auch bei Mehrkernsystemen Multiplexing durchgeführt werden, um alle Threads zu behandeln. Allerdings ist die Frequenz eines Threads oder seine durchschnittlich zugewiesene Zeit deutlich höher, da sich die Last auf mehrere Recheneinheiten verteilt.\\[0.5 cm]
Moderne Mehrkernsysteme zusammen mit effizienten Multiplexverfahren (sowie weiteren Ressource-Sharing- Prozessen) bieten eine hohe Leistungsfähigkeit sowie ein großes Maß an Parallelität und auch auf Einkernprozessoren kann die Parallelisierung von Software, große Vorteile bringen. Die Voraussetzungen an die Software um diese Möglichkeiten in Anspruch zu nehmen, werden im nächsten Kapitel erläutert.
